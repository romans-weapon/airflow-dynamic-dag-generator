from airflow import DAG
from datetime import datetime
from airflow.operators.python_operator import PythonOperator
from airflow.operators.http_operator import SimpleHttpOperator
import json

default_args= {
 'owner': 'Airflow POC',
 'depends_on_past': True,
 'email': '{{ payload.email }}',
 'start_date': datetime(2020,1,1)
}

def my_function(x):
    return x + " is a must have tool for Data Engineers."

dag = DAG(
    dag_id="{{ payload.dag_name }}_{{ payload.dag_id }}",
    default_args=default_args,
    schedule_interval="{{ payload.schedule_interval }}",
    catchup={{payload.catchup or False}})

t1 = PythonOperator(
    task_id='python_sample_task',
    python_callable=my_function,
    op_kwargs={"x": "Apache Airflow"},
    dag=dag
)

t2  = SimpleHttpOperator(
    task_id='python etl api call',
    method='POST',
    http_conn_id='{{ payload.connection_id }}',
    endpoint='/api/app/random_app',
    headers={"Content-Type": "application/json"},
    data= {"key1":"val1","key2":"val2"},
    dag=dag
 )

t1 >> t2
